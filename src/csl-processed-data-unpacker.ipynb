{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Readme  \nThis code is intended for use as a base for building models on.  You should include the data from [Causal Structure Learning from Event Sequences](https://www.kaggle.com/datasets/lukemiller1987/causal-structure-learning-from-event-sequences)\n## Libraries\nThis code base was implemented in Python 3.10.12.  If there is a mismatch, please run:  \n  \n`conda create --name myenv python=3.10.12  \nconda activate myenv  \nconda install jupyter  \njupyter notebook  `","metadata":{}},{"cell_type":"markdown","source":"### Install Specific Package Versions\n- Uses `pip` to install specific versions of the following Python packages:\n    - `scipy`: version 1.11.2\n    - `numpy`: version 1.23.5\n    - `pandas`: version 2.0.3\n## Import and Version Check\nImports the installed packages and performs a version check using `assert` statements.\n## Check Python Version\nChecks if the Python version starts with '3.10.12'.\n## Import Standard Libraries\nImports `os` and `pickle`, whose versions are tied to the Python version.\n\nEach `assert`statement checks if the current package or Python version matches the expected version. If not, it raises an exception displaying the expected and current versions.","metadata":{}},{"cell_type":"code","source":"# Install specific versions\n!pip install scipy==1.11.2 numpy==1.23.5 pandas==2.0.3\n\n# Import specific versions\nimport scipy\nassert scipy.__version__ == '1.11.2', f'Expected scipy version 1.11.2, got {scipy.__version__}'\n\nimport numpy as np\nassert np.__version__ == '1.23.5', f'Expected numpy version 1.23.5, got {np.__version__}'\n\nimport pandas as pd\nassert pd.__version__ == '2.0.3', f'Expected pandas version 2.0.3, got {pd.__version__}'\n\nimport sys\nassert sys.version.startswith('3.10.12'), f'Expected Python version 3.10.12, got {sys.version}'\n\n# os and pickle are standard libraries and their versions are tied to Python version.\nimport os\nimport pickle\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-07T12:29:11.231716Z","iopub.execute_input":"2023-09-07T12:29:11.232097Z","iopub.status.idle":"2023-09-07T12:29:26.637499Z","shell.execute_reply.started":"2023-09-07T12:29:11.232068Z","shell.execute_reply":"2023-09-07T12:29:26.636072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Function Overview: `convert_compressed_to_uncompressed`\n\n### Purpose\nConverts a compressed dataset to its normal form. Intended for unpacking datasets that are part of \"Causal Structure Learning from Event Sequences.\" \n\n### Parameters\n- `dataset_num`: The dataset number to process, ranging from 0 to 3.\n- `slice_num`: The slice of the dataset to process, ranging from 0 to 1023.\n\n### Implementation Details\n\n#### 1. Load Compressed Data\n- Constructs paths to compressed data files (.npz), causal data files (.pkl), and alarm ID mappings (.pkl).\n- Reads in the compresseed data using NumPy's `np.load` function and constructs a compressed sparse row (CSR) matrix.\n\n#### 2. Load Causal Data and Mapping\n- Loads causal data and the alarm ID mapping from their respective pickle files.\n- Converts causal data to NumPy `int8` arrays.\n\n#### 3. Initialize Dictionary\n- Initializes an empty dictionary (`data_dict`) to hold the uncompressed data.\n\n#### 4. Conversion to Uncompressed Form\n- Iterates through each alarm ID index in the compressed matrix.\n- For each alarm, constructs an array representing involved devices at each time stamp (0-1023).\n- Adds these arrays to `data_dict` under their respective alarm IDs.\n\n#### 5. Final DataFrame\n- Converts `data_dict` to a Pandas DataFrame.\n- Appends a new column, `causal_data`, to the DataFrame, mapping the causal data to each alarm ID index.\n\n### Output\n- Returns an uncompressed DataFrame containing the expanded dataset and causal information.\n\n### Required Libraries\n- NumPy\n- Pandas\n- pickle\n","metadata":{}},{"cell_type":"code","source":"def convert_compressed_to_uncompressed(dataset_num, slice_num):\n    # Load sparse data\n    base_path = '/kaggle/input/causal-structure-learning-from-event-sequences/'\n    data_path = f'{base_path}CSL Sparse Datasets/dataset_{dataset_num}/subfolder_{(slice_num//256)}/dataset_{dataset_num}_{slice_num}.npz'\n    causal_path = f'{base_path}CSL Sparse Datasets/dataset_{dataset_num}/subfolder_{(slice_num//256)}/dataset_{dataset_num}_{slice_num}_causal.pkl'\n    mapping_path = f'{base_path}dataset_{dataset_num}_alarm_id_mapping.pkl'\n    loaded_data = np.load(data_path)\n    sparse_mat = csr_matrix((loaded_data['data'], loaded_data['indices'], loaded_data['indptr']), shape=loaded_data['shape'])\n    \n    # Load causal data and mapping\n    with open(causal_path, 'rb') as f:\n        causal_data = pickle.load(f)\n\n    causal_data = [np.array(arr, dtype=np.int8) for arr in causal_data]  # Convert to NumPy int8 arrays\n\n    with open(mapping_path, 'rb') as f:\n        alarm_id_mapping = pickle.load(f)\n\n    # Initialize the dictionary to hold the dense data\n    data_dict = {}\n    \n    for alarm_id_idx in range(sparse_mat.shape[0]):\n        alarm_id = alarm_id_mapping[alarm_id_idx]  # Retrieve actual alarm_id from the mapping\n        row = sparse_mat.getrow(alarm_id_idx).toarray().flatten()\n        \n        # Initialize an empty list to hold device arrays for each time_stamp\n        device_arrays_for_alarm = []\n        \n        for time_stamp in range(1024):  # 2 ** 10 = 1024\n            # Initialize a zero array of size 2**8\n            device_array = np.zeros(2**8, dtype=int)\n            \n            for device_id in range(2**8):\n                col_index = time_stamp * 2**8 + device_id\n                \n                if row[col_index] != 0:\n                    device_array[device_id] = 1  # Mark device as involved\n\n            # Append the device_array to the list for this alarm_id\n            device_arrays_for_alarm.append(device_array)\n        \n        # Insert the full list of device arrays for this alarm_id into the dictionary\n        data_dict[alarm_id] = device_arrays_for_alarm\n\n    # Convert to a DataFrame\n    final_df = pd.DataFrame.from_dict(data_dict, orient='index', columns=range(1024))\n\n    # Add causal_data column to DataFrame\n    final_df['causal_data'] = final_df.index.map(lambda idx: causal_data[idx])\n\n    return final_df","metadata":{"execution":{"iopub.status.busy":"2023-09-05T19:27:54.404592Z","iopub.execute_input":"2023-09-05T19:27:54.404967Z","iopub.status.idle":"2023-09-05T19:27:54.418631Z","shell.execute_reply.started":"2023-09-05T19:27:54.404937Z","shell.execute_reply":"2023-09-05T19:27:54.416767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Code Snippet Overview\n\n### Code Functionality\nThis code snippet calls the `convert_compressed_to_uncompressed` function with `dataset_num` set to 0 and `slice_num` set to 0. The function's output is then stored in the variable `ds_0_0`.\n\n### Parameters\n- `dataset_num = 0`: Targets the first dataset.\n- `slice_num = 0`: Targets the first slice within the dataset.\n\n### Output\n`ds_0_0` will contain the uncompressed form of the first slice (`slice_num = 0`) from the first dataset (`dataset_num = 0`).","metadata":{}},{"cell_type":"code","source":"dataset_num = 0\nslice_num = 0\nds_0_0 = convert_compressed_to_uncompressed(dataset_num, slice_num)","metadata":{"execution":{"iopub.status.busy":"2023-09-05T19:27:54.420675Z","iopub.execute_input":"2023-09-05T19:27:54.421064Z","iopub.status.idle":"2023-09-05T19:27:56.358037Z","shell.execute_reply.started":"2023-09-05T19:27:54.421033Z","shell.execute_reply":"2023-09-05T19:27:56.357096Z"},"trusted":true},"execution_count":null,"outputs":[]}]}