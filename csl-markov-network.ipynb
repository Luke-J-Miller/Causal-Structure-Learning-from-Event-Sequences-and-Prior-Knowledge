{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport pickle\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-31T12:59:15.529793Z","iopub.execute_input":"2023-08-31T12:59:15.530342Z","iopub.status.idle":"2023-08-31T12:59:15.538233Z","shell.execute_reply.started":"2023-08-31T12:59:15.530300Z","shell.execute_reply":"2023-08-31T12:59:15.536875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alarm1 = pd.read_csv('/kaggle/input/causal-structure-learning-from-event-sequences/datasets/dataset_1/alarm.csv')\ncausal1 = np.load('/kaggle/input/causal-structure-learning-from-event-sequences/datasets/dataset_1/causal_prior.npy' , allow_pickle = True)\n\nalarm2 = pd.read_csv('/kaggle/input/causal-structure-learning-from-event-sequences/datasets/dataset_2/alarm.csv')\ncausal2 = np.load('/kaggle/input/causal-structure-learning-from-event-sequences/datasets/dataset_2/causal_prior.npy' , allow_pickle = True)\n\nalarm3 = pd.read_csv('/kaggle/input/causal-structure-learning-from-event-sequences/datasets/dataset_3/alarm.csv')\ncausal3 = np.load('/kaggle/input/causal-structure-learning-from-event-sequences/datasets/dataset_3/causal_prior.npy' , allow_pickle = True)\n\nalarm4 = pd.read_csv('/kaggle/input/causal-structure-learning-from-event-sequences/datasets/dataset_4/alarm.csv')\ncausal4 = np.load('/kaggle/input/causal-structure-learning-from-event-sequences/datasets/dataset_4/causal_prior.npy' , allow_pickle = True)\n\nrca1 = pd.read_csv('/kaggle/input/causal-structure-learning-from-event-sequences/datasets/dataset_1/rca_prior.csv')\ntopology1 = np.load('/kaggle/input/causal-structure-learning-from-event-sequences/datasets/dataset_1/topology.npy' , allow_pickle = True)\nrca2 = pd.read_csv('/kaggle/input/causal-structure-learning-from-event-sequences/datasets/dataset_2/rca_prior.csv')\ntopology2 = np.load('/kaggle/input/causal-structure-learning-from-event-sequences/datasets/dataset_2/topology.npy' , allow_pickle = True)\nrca3 = pd.read_csv('/kaggle/input/causal-structure-learning-from-event-sequences/datasets/dataset_3/rca_prior.csv')\ntopology3 = np.load('/kaggle/input/causal-structure-learning-from-event-sequences/datasets/dataset_3/topology.npy' , allow_pickle = True)","metadata":{"execution":{"iopub.status.busy":"2023-08-31T12:59:15.588843Z","iopub.execute_input":"2023-08-31T12:59:15.589665Z","iopub.status.idle":"2023-08-31T12:59:15.948108Z","shell.execute_reply.started":"2023-08-31T12:59:15.589626Z","shell.execute_reply":"2023-08-31T12:59:15.946696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MarkovModel:\n    def __init__(self, y):\n        self.transition_matrix = np.zeros_like(y, dtype=float)\n        self.y = y\n        self.time_window = 300\n\n    def train(self, X):\n        alarm_to_node = {alarm: index for index, alarm in enumerate(sorted(np.unique(X['alarm_id'])))}\n\n        for i, row in X.iterrows():\n            current_alarm = row['alarm_id']\n            current_time = row['start_timestamp']\n            current_node = alarm_to_node[current_alarm]\n\n            # Identify potential alarms that could be caused by the current alarm\n            potential_cause_nodes = np.where(self.y[current_node, :] != -1)[0]\n\n            future_alarms = X[(X['start_timestamp'] > current_time) & \n                              (X['start_timestamp'] <= current_time + self.time_window)]\n\n            for _, future_row in future_alarms.iterrows():\n                next_alarm = future_row['alarm_id']\n                next_node = alarm_to_node[next_alarm]\n\n                if next_node in potential_cause_nodes:  # Only consider causally related alarms\n                    self.transition_matrix[current_node, next_node] += 1\n\n        # Normalize\n        row_sums = self.transition_matrix.sum(axis=1, keepdims=True)\n        row_sums[row_sums == 0] = 1  # Avoid division by zero\n        self.transition_matrix /= row_sums\n\n        \n    def predict_matrix(self, X_test):\n        # Get unique and sorted alarms from X_test\n        unique_sorted_alarms = sorted(np.unique(X_test['alarm_id']))\n        alarm_to_node_test = {alarm: index for index, alarm in enumerate(unique_sorted_alarms)}\n\n        # Initialize predicted_matrix\n        blank_y_pred = [[-1 for _ in unique_sorted_alarms] for _ in unique_sorted_alarms]\n        predicted_matrix = np.array(blank_y_pred)\n\n        for alarm1 in unique_sorted_alarms:\n            if alarm1 not in self.alarm_to_node:\n                continue\n            i = self.alarm_to_node[alarm1]\n            i_test = alarm_to_node_test[alarm1]\n\n            for alarm2 in unique_sorted_alarms:\n                if alarm2 not in self.alarm_to_node:\n                    continue\n                j = self.alarm_to_node[alarm2]\n                j_test = alarm_to_node_test[alarm2]\n\n                if self.transition_matrix[i, j] > 0:  # If observed in training data, predict a connection\n                    predicted_matrix[i_test, j_test] = 1\n\n        return predicted_matrix\n\n\n\n    def evaluate(self, y_test):\n        pass\n    \n    \n    def fine_tune(self):\n        pass\n    \n    def deploy(self):\n        pass","metadata":{"execution":{"iopub.status.busy":"2023-08-31T12:59:15.950625Z","iopub.execute_input":"2023-08-31T12:59:15.951023Z","iopub.status.idle":"2023-08-31T12:59:15.962428Z","shell.execute_reply.started":"2023-08-31T12:59:15.950993Z","shell.execute_reply":"2023-08-31T12:59:15.961007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_features(dataset_list):\n    new_dataset_list = []\n    for alarm, causal in dataset_list:\n        \n        alarm['duration'] = alarm['end_timestamp'] - alarm['start_timestamp']\n        alarm_one_hot = pd.get_dummies(alarm['alarm_id'], prefix='alarm')\n        device_one_hot = pd.get_dummies(alarm['device_id'], prefix='device')\n\n        # Time-windowed aggregations - Likely unnecessary as handled in training.\n        alarm['count_last_5min'] = alarm.groupby('device_id')['alarm_id'].transform(lambda x: x.rolling(window=300, min_periods=0).count()).astype(int)\n        alarm['count_last_3min'] = alarm.groupby('device_id')['alarm_id'].transform(lambda x: x.rolling(window=180, min_periods=0).count()).astype(int)\n\n        # Alarm sequences\n        alarm['last_alarm'] = alarm.groupby('device_id')['alarm_id'].shift().fillna(-1).astype(int)  # Fill NaN with -1\n\n        # Elapsed time\n        alarm['time_since_last_alarm'] = alarm.groupby('device_id')['start_timestamp'].diff().fillna(-1).astype(int)  # Fill NaN with -1\n        alarm = pd.concat([alarm, alarm_one_hot, device_one_hot], axis=1)\n        new_dataset_list.append((alarm, causal))\n        \n    return new_dataset_list","metadata":{"execution":{"iopub.status.busy":"2023-08-31T12:59:15.964938Z","iopub.execute_input":"2023-08-31T12:59:15.965377Z","iopub.status.idle":"2023-08-31T12:59:15.983388Z","shell.execute_reply.started":"2023-08-31T12:59:15.965342Z","shell.execute_reply":"2023-08-31T12:59:15.982088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(X_train, y_train):\n    # Model architecture\n    # Model training\n    return trained_model\n","metadata":{"execution":{"iopub.status.busy":"2023-08-31T12:59:15.986420Z","iopub.execute_input":"2023-08-31T12:59:15.987890Z","iopub.status.idle":"2023-08-31T12:59:16.004488Z","shell.execute_reply.started":"2023-08-31T12:59:15.987812Z","shell.execute_reply":"2023-08-31T12:59:16.003472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef evaluate_model(trained_model, X_test, y_test):\n    # Calculate metrics\n    return accuracy, precision, recall\n","metadata":{"execution":{"iopub.status.busy":"2023-08-31T12:59:16.006374Z","iopub.execute_input":"2023-08-31T12:59:16.007855Z","iopub.status.idle":"2023-08-31T12:59:16.020506Z","shell.execute_reply.started":"2023-08-31T12:59:16.007806Z","shell.execute_reply":"2023-08-31T12:59:16.019099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fine_tune_model(trained_model):\n    # Hyperparameter tuning\n    return fine_tuned_model\n","metadata":{"execution":{"iopub.status.busy":"2023-08-31T12:59:16.022035Z","iopub.execute_input":"2023-08-31T12:59:16.022524Z","iopub.status.idle":"2023-08-31T12:59:16.034413Z","shell.execute_reply.started":"2023-08-31T12:59:16.022485Z","shell.execute_reply":"2023-08-31T12:59:16.033038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def deploy_model(fine_tuned_model, new_data):\n    # Make predictions\n    return root_causes\n","metadata":{"execution":{"iopub.status.busy":"2023-08-31T12:59:16.037792Z","iopub.execute_input":"2023-08-31T12:59:16.038405Z","iopub.status.idle":"2023-08-31T12:59:16.048382Z","shell.execute_reply.started":"2023-08-31T12:59:16.038356Z","shell.execute_reply":"2023-08-31T12:59:16.047054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_list = [(alarm1, causal1), (alarm2, causal2), (alarm3, causal3), (alarm4, causal4)]\ndataset_list = create_features(dataset_list)","metadata":{"execution":{"iopub.status.busy":"2023-08-31T12:59:16.064807Z","iopub.execute_input":"2023-08-31T12:59:16.065555Z","iopub.status.idle":"2023-08-31T12:59:17.310411Z","shell.execute_reply.started":"2023-08-31T12:59:16.065508Z","shell.execute_reply":"2023-08-31T12:59:17.308956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"counter = 0\ndataset_dict = {}\n\nfor i in range(4):\n    for j in range(4):\n        if i != j:\n            X_train, y_train = dataset_list[i]\n            X_test, y_test = dataset_list[j]\n            \n            dataset_dict[f'dataset_{counter}'] = {\n                'X_train': X_train,\n                'y_train': y_train,\n                'X_test': X_test,\n                'y_test': y_test\n            }\n            \n            counter += 1\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-31T12:59:17.312478Z","iopub.execute_input":"2023-08-31T12:59:17.312975Z","iopub.status.idle":"2023-08-31T12:59:17.321350Z","shell.execute_reply.started":"2023-08-31T12:59:17.312944Z","shell.execute_reply":"2023-08-31T12:59:17.319535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dont_run():# Create an instance of the MarkovModel\n    markov_model = MarkovModel(num_nodes)\n\n    # Train the model using training data\n    X_train, y_train = dataset_dict['dataset_0']['X_train'], dataset_dict['dataset_0']['y_train']\n    markov_model.train(X_train, y_train)\n\n    # Make predictions using test data\n    X_test = dataset_dict['dataset_1']['X_test']\n    predictions = markov_model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-31T12:59:58.376938Z","iopub.execute_input":"2023-08-31T12:59:58.377384Z","iopub.status.idle":"2023-08-31T12:59:58.385180Z","shell.execute_reply.started":"2023-08-31T12:59:58.377352Z","shell.execute_reply":"2023-08-31T12:59:58.383918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alarm1\n","metadata":{"execution":{"iopub.status.busy":"2023-08-31T13:35:38.666439Z","iopub.execute_input":"2023-08-31T13:35:38.666893Z","iopub.status.idle":"2023-08-31T13:35:38.687713Z","shell.execute_reply.started":"2023-08-31T13:35:38.666859Z","shell.execute_reply":"2023-08-31T13:35:38.686165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for num, row in enumerate(causal1):\n    print(num, row)\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-08-31T13:31:41.434834Z","iopub.execute_input":"2023-08-31T13:31:41.435228Z","iopub.status.idle":"2023-08-31T13:31:41.459825Z","shell.execute_reply.started":"2023-08-31T13:31:41.435200Z","shell.execute_reply":"2023-08-31T13:31:41.458384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for num, row in enumerate(topology1):\n    print(num, row)","metadata":{"execution":{"iopub.status.busy":"2023-08-31T13:34:47.859550Z","iopub.execute_input":"2023-08-31T13:34:47.860022Z","iopub.status.idle":"2023-08-31T13:34:47.874252Z","shell.execute_reply.started":"2023-08-31T13:34:47.859991Z","shell.execute_reply":"2023-08-31T13:34:47.872852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}