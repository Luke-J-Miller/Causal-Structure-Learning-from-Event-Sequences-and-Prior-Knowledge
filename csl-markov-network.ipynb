{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport pickle\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-01T14:31:03.939999Z","iopub.execute_input":"2023-09-01T14:31:03.940412Z","iopub.status.idle":"2023-09-01T14:31:03.946710Z","shell.execute_reply.started":"2023-09-01T14:31:03.940381Z","shell.execute_reply":"2023-09-01T14:31:03.945272Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def g_score(true_positives, false_positives, false_negatives):\n    return max(0, true_positives - false_positives) / (true_positives + false_negatives + 1e-7)  # Added epsilon to avoid division by zero\n\ndef rank_score(g_scores):\n    return sum(1**g for g in g_scores)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GCNLayer:\n    def __init__(self, input_dim, output_dim):\n        self.weights = initialize_weights(input_dim, output_dim)\n        self.grads = np.zeros_like(self.weights)\n\n    def relu(self, x):\n        return np.maximum(0, x)\n\n    def sigmoid(self, x):\n        return 1 / (1 + np.exp(-x))\n\n    def forward(self, A, X):\n        return self.relu(A @ X @ self.weights)\n    \n    def backward(self, d_loss):\n        # Compute gradients using the chain rule\n        self.grads = d_loss  # Update this as per your specific loss and activation\n        return self.grads\n\nclass GCN:\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        self.gcn1 = GCNLayer(input_dim, hidden_dim)\n        self.gcn2 = GCNLayer(hidden_dim, output_dim)\n\n    def forward(self, A, X):\n        self.H1 = self.gcn1.forward(A, X)\n        self.H2 = self.gcn2.forward(A, self.H1)\n        return self.H2\n\n    def backward(self, d_loss):\n        # Backward pass for the second layer\n        d_loss2 = self.gcn2.backward(d_loss)\n        \n        # Backward pass for the first layer\n        d_loss1 = self.gcn1.backward(d_loss2)\n        \n    def update_weights(self, learning_rate):\n        self.gcn1.weights -= learning_rate * self.gcn1.grads\n        self.gcn2.weights -= learning_rate * self.gcn2.grads\n","metadata":{"execution":{"iopub.status.busy":"2023-09-01T14:31:03.952573Z","iopub.execute_input":"2023-09-01T14:31:03.952938Z","iopub.status.idle":"2023-09-01T14:31:03.968278Z","shell.execute_reply.started":"2023-09-01T14:31:03.952909Z","shell.execute_reply":"2023-09-01T14:31:03.966873Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def create_features(dataset_list):\n    new_dataset_list = []\n    for alarm, causal in dataset_list:\n        \n        alarm['duration'] = alarm['end_timestamp'] - alarm['start_timestamp']\n        alarm_one_hot = pd.get_dummies(alarm['alarm_id'], prefix='alarm')\n        device_one_hot = pd.get_dummies(alarm['device_id'], prefix='device')\n\n        # Time-windowed aggregations - Likely unnecessary as handled in training.\n        alarm['count_last_5min'] = alarm.groupby('device_id')['alarm_id'].transform(lambda x: x.rolling(window=300, min_periods=0).count()).astype(int)\n        alarm['count_last_3min'] = alarm.groupby('device_id')['alarm_id'].transform(lambda x: x.rolling(window=180, min_periods=0).count()).astype(int)\n\n        # Alarm sequences\n        alarm['last_alarm'] = alarm.groupby('device_id')['alarm_id'].shift().fillna(-1).astype(int)  # Fill NaN with -1\n\n        # Elapsed time\n        alarm['time_since_last_alarm'] = alarm.groupby('device_id')['start_timestamp'].diff().fillna(-1).astype(int)  # Fill NaN with -1\n        alarm = pd.concat([alarm, alarm_one_hot, device_one_hot], axis=1)\n        flattened_causal = causal.flatten()\n        new_dataset_list.append((alarm, flattened_causal))\n        \n    return new_dataset_list","metadata":{"execution":{"iopub.status.busy":"2023-09-01T14:31:03.970274Z","iopub.execute_input":"2023-09-01T14:31:03.970662Z","iopub.status.idle":"2023-09-01T14:31:03.986482Z","shell.execute_reply.started":"2023-09-01T14:31:03.970628Z","shell.execute_reply":"2023-09-01T14:31:03.985017Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alarm1 = pd.read_csv('/kaggle/input/causal-structure-learning-from-event-sequences/datasets/dataset_1/alarm.csv')\ncausal1 = np.load('/kaggle/input/causal-structure-learning-from-event-sequences/datasets/dataset_1/causal_prior.npy' , allow_pickle = True)\n\nalarm2 = pd.read_csv('/kaggle/input/causal-structure-learning-from-event-sequences/datasets/dataset_2/alarm.csv')\ncausal2 = np.load('/kaggle/input/causal-structure-learning-from-event-sequences/datasets/dataset_2/causal_prior.npy' , allow_pickle = True)\n\nalarm3 = pd.read_csv('/kaggle/input/causal-structure-learning-from-event-sequences/datasets/dataset_3/alarm.csv')\ncausal3 = np.load('/kaggle/input/causal-structure-learning-from-event-sequences/datasets/dataset_3/causal_prior.npy' , allow_pickle = True)\n\nalarm4 = pd.read_csv('/kaggle/input/causal-structure-learning-from-event-sequences/datasets/dataset_4/alarm.csv')\ncausal4 = np.load('/kaggle/input/causal-structure-learning-from-event-sequences/datasets/dataset_4/causal_prior.npy' , allow_pickle = True)\n\nrca1 = pd.read_csv('/kaggle/input/causal-structure-learning-from-event-sequences/datasets/dataset_1/rca_prior.csv')\ntopology1 = np.load('/kaggle/input/causal-structure-learning-from-event-sequences/datasets/dataset_1/topology.npy' , allow_pickle = True)\nrca2 = pd.read_csv('/kaggle/input/causal-structure-learning-from-event-sequences/datasets/dataset_2/rca_prior.csv')\ntopology2 = np.load('/kaggle/input/causal-structure-learning-from-event-sequences/datasets/dataset_2/topology.npy' , allow_pickle = True)\nrca3 = pd.read_csv('/kaggle/input/causal-structure-learning-from-event-sequences/datasets/dataset_3/rca_prior.csv')\ntopology3 = np.load('/kaggle/input/causal-structure-learning-from-event-sequences/datasets/dataset_3/topology.npy' , allow_pickle = True)","metadata":{"execution":{"iopub.status.busy":"2023-09-01T14:31:03.988935Z","iopub.execute_input":"2023-09-01T14:31:03.989431Z","iopub.status.idle":"2023-09-01T14:31:04.313280Z","shell.execute_reply.started":"2023-09-01T14:31:03.989378Z","shell.execute_reply":"2023-09-01T14:31:04.311771Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"test = causal1.flatten()\nprint(test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-01T14:33:23.225260Z","iopub.execute_input":"2023-09-01T14:33:23.225688Z","iopub.status.idle":"2023-09-01T14:33:23.231984Z","shell.execute_reply.started":"2023-09-01T14:33:23.225652Z","shell.execute_reply":"2023-09-01T14:33:23.230636Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"(1521,)\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset_list = [(alarm1, causal1), (alarm2, causal2), (alarm3, causal3), (alarm4, causal4)]\n\ndataset_list = create_features(dataset_list)\nfor al, ca in dataset_list:\n    print(al.shape)\n    print(ca.shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-01T14:34:52.420764Z","iopub.execute_input":"2023-09-01T14:34:52.421869Z","iopub.status.idle":"2023-09-01T14:34:53.476119Z","shell.execute_reply.started":"2023-09-01T14:34:52.421816Z","shell.execute_reply":"2023-09-01T14:34:53.474642Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"(141853, 83)\n(1521,)\n(132688, 100)\n(2401,)\n(198962, 79)\n(961,)\n(126803, 139)\n(900,)\n","output_type":"stream"}]},{"cell_type":"code","source":"counter = 0\ndataset_dict = {}\n\nfor i in range(4):\n    for j in range(4):\n        if i != j:\n            X_train, y_train = dataset_list[i]\n            X_test, y_test = dataset_list[j]\n            \n            dataset_dict[f'dataset_{counter}'] = {\n                'X_train': X_train,\n                'y_train': y_train,\n                'X_test': X_test,\n                'y_test': y_test\n            }\n            \n            counter += 1\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-01T14:31:05.344718Z","iopub.execute_input":"2023-09-01T14:31:05.345490Z","iopub.status.idle":"2023-09-01T14:31:05.351969Z","shell.execute_reply.started":"2023-09-01T14:31:05.345449Z","shell.execute_reply":"2023-09-01T14:31:05.350941Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def dont_run():# Create an instance of the MarkovModel\n    markov_model = MarkovModel(num_nodes)\n\n    # Train the model using training data\n    X_train, y_train = dataset_dict['dataset_0']['X_train'], dataset_dict['dataset_0']['y_train']\n    markov_model.train(X_train, y_train)\n\n    # Make predictions using test data\n    X_test = dataset_dict['dataset_1']['X_test']\n    predictions = markov_model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-01T14:31:05.353682Z","iopub.execute_input":"2023-09-01T14:31:05.354130Z","iopub.status.idle":"2023-09-01T14:31:05.374473Z","shell.execute_reply.started":"2023-09-01T14:31:05.354094Z","shell.execute_reply":"2023-09-01T14:31:05.373148Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"for al, ca in dataset_list:\n    print(al.shape)\n    print(ca.shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-01T14:31:05.376038Z","iopub.execute_input":"2023-09-01T14:31:05.376601Z","iopub.status.idle":"2023-09-01T14:31:05.391061Z","shell.execute_reply.started":"2023-09-01T14:31:05.376561Z","shell.execute_reply":"2023-09-01T14:31:05.389729Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"(141853, 83)\n(1521,)\n(132688, 100)\n(2401,)\n(198962, 79)\n(961,)\n(126803, 139)\n(900,)\n","output_type":"stream"}]}]}